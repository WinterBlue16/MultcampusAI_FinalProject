{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 17:14:51) \n",
      "[GCC 7.2.0]\n",
      "1.5.0\n",
      "4.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/lab02'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import dlib\n",
    "import cv2\n",
    "print(cv2.__version__)\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from imutils import face_utils\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()+'/File'\n",
    "shape_predict = path +'/shapepre/shape_predictor_68_face_landmarks.dat'\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(shape_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11403\n",
      "8606\n",
      "8096\n"
     ]
    }
   ],
   "source": [
    "img = os.getcwd()+'/imagefile_test/trteva/train'\n",
    "e01tr = []\n",
    "e02tr = []\n",
    "e03tr = []\n",
    "\n",
    "for i in range(0,11403):\n",
    "    e01tr.append(cv2.imread(img+'/E01/'+str(i)+'.jpg'))\n",
    "        \n",
    "e01tr = list(filter(None.__ne__, e01tr))\n",
    "\n",
    "for i in range(0,8606):\n",
    "    e02tr.append(cv2.imread(img+'/E02/'+str(i)+'.jpg'))\n",
    "        \n",
    "e02tr = list(filter(None.__ne__, e02tr))\n",
    "\n",
    "for i in range(0,8096):\n",
    "    e03tr.append(cv2.imread(img+'/E03/'+str(i)+'.jpg'))\n",
    "            \n",
    "e03tr = list(filter(None.__ne__, e03tr))\n",
    "\n",
    "print(len(e01tr))\n",
    "print(len(e02tr))\n",
    "print(len(e03tr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570\n",
      "1146\n",
      "1090\n",
      "******\n",
      "1570\n",
      "1145\n",
      "1089\n"
     ]
    }
   ],
   "source": [
    "img = os.getcwd()+'/imagefile_test/trteva/val'\n",
    "e01va = []\n",
    "e02va = []\n",
    "e03va = []\n",
    "\n",
    "for i in range(0,3140):\n",
    "    e01va.append(cv2.imread(img+'/E01/'+str(i)+'.jpg'))\n",
    "      \n",
    "    \n",
    "e01va = list(filter(None.__ne__, e01va))\n",
    "\n",
    "for i in range(0,2291):\n",
    "    e02va.append(cv2.imread(img+'/E02/'+str(i)+'.jpg'))\n",
    "      \n",
    "    \n",
    "e02va = list(filter(None.__ne__, e02va))\n",
    "\n",
    "for i in range(0,2179):\n",
    "    e03va.append(cv2.imread(img+'/E03/'+str(i)+'.jpg'))\n",
    "      \n",
    "    \n",
    "e03va = list(filter(None.__ne__, e03va))\n",
    "\n",
    "print(len(e01va))\n",
    "print(len(e02va))\n",
    "print(len(e03va))\n",
    "print(\"******\")\n",
    "\n",
    "\n",
    "img = os.getcwd()+'/imagefile_test/trteva/test'\n",
    "e01te = []\n",
    "e02te = []\n",
    "e03te = []\n",
    "\n",
    "for i in range(0,3140):\n",
    "    e01te.append(cv2.imread(img+'/E01/'+str(i)+'.jpg'))\n",
    "      \n",
    "    \n",
    "e01te = list(filter(None.__ne__, e01te))\n",
    "\n",
    "for i in range(0,2291):\n",
    "    e02te.append(cv2.imread(img+'/E02/'+str(i)+'.jpg'))\n",
    "      \n",
    "    \n",
    "e02te = list(filter(None.__ne__, e02te))\n",
    "\n",
    "for i in range(0,2179):\n",
    "    e03te.append(cv2.imread(img+'/E03/'+str(i)+'.jpg'))\n",
    "      \n",
    "    \n",
    "e03te = list(filter(None.__ne__, e03te))\n",
    "\n",
    "print(len(e01te))\n",
    "print(len(e02te))\n",
    "print(len(e03te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e01tr 좌표담기끝\n",
      "e02tr 좌표담기끝\n",
      "e03tr 좌표담기끝\n",
      "트레인셋 구축\n",
      "e01va 좌표담기끝\n",
      "e02va 좌표담기끝\n",
      "e03va 좌표담기끝\n",
      "벨리데이션 구축\n",
      "e01te 좌표담기끝\n",
      "e02te 좌표담기끝\n",
      "e03te 좌표담기끝\n",
      "테스트셋 구축\n"
     ]
    }
   ],
   "source": [
    "liste_train = []\n",
    "tr_y = []\n",
    "tr_error = []\n",
    "for i in e01tr:\n",
    "    e01tr_gray = cv2.cvtColor(i, cv2.COLOR_BGR2GRAY)\n",
    "    rects1 = detector(e01tr_gray, 1)\n",
    "                        \n",
    "    for face1 in rects1:\n",
    "\n",
    "        shape = predictor(i, face1) #얼굴에서 68개 점 찾기\n",
    "#         if len(shape.parts()) != 68 :\n",
    "#             tr_error.append(i)\n",
    "        for p in shape.parts():\n",
    "            liste_train.append([p.x, p.y])\n",
    "        if len(liste_train)%68 != 0 :\n",
    "            tr_error.append(i)\n",
    "        tr_y.append(0)   \n",
    "   \n",
    "\n",
    "print(\"e01tr 좌표담기끝\")\n",
    "        \n",
    "\n",
    "\n",
    "for i in e02tr:\n",
    "    e02tr_gray = cv2.cvtColor(i, cv2.COLOR_BGR2GRAY)\n",
    "    rects2 = detector(e02tr_gray, 1)\n",
    "                        \n",
    "    for face2 in rects2:\n",
    "\n",
    "        shape = predictor(i, face2) #얼굴에서 68개 점 찾기\n",
    "#         if len(shape.parts()) != 68 :\n",
    "#             tr_error.append(i)\n",
    "        for p in shape.parts():\n",
    "            liste_train.append([p.x, p.y])\n",
    "        if len(liste_train)%68 != 0 :\n",
    "            tr_error.append(i)\n",
    "        tr_y.append(1)    \n",
    "    \n",
    "\n",
    "            \n",
    "print(\"e02tr 좌표담기끝\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in e03tr:\n",
    "    e03tr_gray = cv2.cvtColor(i, cv2.COLOR_BGR2GRAY)\n",
    "    rects3 = detector(e03tr_gray, 1)\n",
    "                        \n",
    "    for face3 in rects3:\n",
    "\n",
    "        shape = predictor(i, face3) #얼굴에서 68개 점 찾기\n",
    "#         if len(shape.parts()) != 68 :\n",
    "#             tr_error.append(i)\n",
    "        for p in shape.parts():\n",
    "            liste_train.append([p.x, p.y])\n",
    "        if len(liste_train)%68 != 0 :\n",
    "            tr_error.append(i)\n",
    "        tr_y.append(2)    \n",
    "    \n",
    "\n",
    "    \n",
    "print(\"e03tr 좌표담기끝\")\n",
    "\n",
    "\n",
    "npe_train = np.array(liste_train)\n",
    "\n",
    "train_x = npe_train.reshape(-1 , 68, 2)\n",
    "\n",
    "\n",
    "print(\"트레인셋 구축\")\n",
    "\n",
    "\n",
    "\n",
    "liste_val = []\n",
    "va_y = []\n",
    "va_error = []\n",
    "for i in e01va:\n",
    "    e01va_gray = cv2.cvtColor(i, cv2.COLOR_BGR2GRAY)\n",
    "    rects1 = detector(e01va_gray, 1)\n",
    "                        \n",
    "    for face1 in rects1:\n",
    "\n",
    "        shape = predictor(i, face1) #얼굴에서 68개 점 찾기\n",
    "#         if len(shape.parts()) != 68 :\n",
    "#             va_error.append(i)\n",
    "        for p in shape.parts():\n",
    "            liste_val.append([p.x, p.y])\n",
    "        if len(liste_val)%68 != 0 :\n",
    "            va_error.append(i)\n",
    "        va_y.append(0)    \n",
    "    \n",
    "\n",
    "\n",
    "print(\"e01va 좌표담기끝\")\n",
    "        \n",
    "\n",
    "\n",
    "for i in e02va:\n",
    "    e02va_gray = cv2.cvtColor(i, cv2.COLOR_BGR2GRAY)\n",
    "    rects2 = detector(e02va_gray, 1)\n",
    "                        \n",
    "    for face2 in rects2:\n",
    "\n",
    "        shape = predictor(i, face2) #얼굴에서 68개 점 찾기\n",
    "#         if len(shape.parts()) != 68 :\n",
    "#             va_error.append(i)\n",
    "        for p in shape.parts():\n",
    "            liste_val.append([p.x, p.y])\n",
    "        if len(liste_val)%68 != 0 :\n",
    "            va_error.append(i)\n",
    "        va_y.append(1)    \n",
    "    \n",
    "\n",
    "\n",
    "print(\"e02va 좌표담기끝\")\n",
    "\n",
    "\n",
    "for i in e03va:\n",
    "    e03va_gray = cv2.cvtColor(i, cv2.COLOR_BGR2GRAY)\n",
    "    rects3 = detector(e03va_gray, 1)\n",
    "                        \n",
    "    for face3 in rects3:\n",
    "\n",
    "        shape = predictor(i, face3) #얼굴에서 68개 점 찾기\n",
    "#         if len(shape.parts()) != 68 :\n",
    "#             va_error.append(i)\n",
    "        for p in shape.parts():\n",
    "            liste_val.append([p.x, p.y])\n",
    "        if len(liste_val)%68 != 0 :\n",
    "            va_error.append(i)\n",
    "        va_y.append(2)    \n",
    "    \n",
    "\n",
    "    \n",
    "print(\"e03va 좌표담기끝\")\n",
    "\n",
    "\n",
    "npe_val = np.array(liste_val)\n",
    "        \n",
    "val_x = npe_val.reshape(-1 , 68, 2)\n",
    "print(\"벨리데이션 구축\")\n",
    "\n",
    "\n",
    "liste_test = []\n",
    "te_y = []\n",
    "te_error = []\n",
    "for i in e01te:\n",
    "    e01te_gray = cv2.cvtColor(i, cv2.COLOR_BGR2GRAY)\n",
    "    rects1 = detector(e01te_gray, 1)\n",
    "                        \n",
    "    for face1 in rects1:\n",
    "\n",
    "        shape = predictor(i, face1) #얼굴에서 68개 점 찾기\n",
    "#         if len(shape.parts()) != 68 :\n",
    "#             te_error.append(i)\n",
    "        for p in shape.parts():\n",
    "            liste_test.append([p.x, p.y])\n",
    "        if len(liste_test)%68 != 0 :\n",
    "            te_error.append(i)\n",
    "        te_y.append(0)    \n",
    "    \n",
    "\n",
    "\n",
    "print(\"e01te 좌표담기끝\")\n",
    "        \n",
    "\n",
    "\n",
    "for i in e02te:\n",
    "    e02te_gray = cv2.cvtColor(i, cv2.COLOR_BGR2GRAY)\n",
    "    rects2 = detector(e02te_gray, 1)\n",
    "                        \n",
    "    for face2 in rects2:\n",
    "\n",
    "        shape = predictor(i, face2) #얼굴에서 68개 점 찾기\n",
    "#         if len(shape.parts()) != 68 :\n",
    "#             te_error.append(i)\n",
    "        for p in shape.parts():\n",
    "            liste_test.append([p.x, p.y])\n",
    "        if len(liste_test)%68 != 0 :\n",
    "            te_error.append(i)\n",
    "        te_y.append(1)    \n",
    "    \n",
    "\n",
    "\n",
    "print(\"e02te 좌표담기끝\")\n",
    "\n",
    "\n",
    "for i in e03te:\n",
    "    e03te_gray = cv2.cvtColor(i, cv2.COLOR_BGR2GRAY)\n",
    "    rects3 = detector(e03te_gray, 1)\n",
    "                        \n",
    "    for face3 in rects3:\n",
    "\n",
    "        shape = predictor(i, face3) #얼굴에서 68개 점 찾기\n",
    "#         if len(shape.parts()) != 68 :\n",
    "#             te_error.append(i)\n",
    "        for p in shape.parts():\n",
    "            liste_test.append([p.x, p.y])\n",
    "        if len(liste_test)%68 != 0 :\n",
    "            te_error.append(i)\n",
    "        te_y.append(2)    \n",
    "    \n",
    "\n",
    "    \n",
    "print(\"e03te 좌표담기끝\")\n",
    "\n",
    "\n",
    "npe_test = np.array(liste_test)\n",
    "        \n",
    "test_x = npe_test.reshape(-1 , 68, 2)\n",
    "\n",
    "\n",
    "print(\"테스트셋 구축\")\n",
    "\n",
    "\n",
    "train_y = tf.keras.utils.to_categorical(tr_y, 3)\n",
    "val_y = tf.keras.utils.to_categorical(va_y, 3)\n",
    "test_y = tf.keras.utils.to_categorical(te_y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = []\n",
    "for p in shape.parts():\n",
    "            k.append([p.x, p.y])\n",
    "\n",
    "len(k)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "e03te_gray = cv2.cvtColor(e03te[1], cv2.COLOR_BGR2GRAY)\n",
    "rects3 = detector(e03te_gray, 1)\n",
    "                        \n",
    "for face3 in rects3:\n",
    "\n",
    "    shape = predictor(i, face3) #얼굴에서 68개 점 찾기\n",
    "    \n",
    "    for p in shape.parts():\n",
    "        k.append([p.x, p.y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1803020"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(liste_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(liste_val)% 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3806\n",
      "252144\n",
      "3708\n",
      "252144\n",
      "3708\n",
      "3708.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(e01va)+len(e02va)+len(e03va))\n",
    "print(len(liste_val))\n",
    "print(len(val_y))\n",
    "print(len(npe_val))\n",
    "print(len(val_x))\n",
    "print(len(npe_val) /68)\n",
    "len(npe_val)% 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28105\n",
      "(26515, 68, 2)\n",
      "(26515, 3)\n",
      "(3708, 68, 2)\n",
      "(3708, 3)\n",
      "(3678, 68, 2)\n",
      "(3678, 3)\n"
     ]
    }
   ],
   "source": [
    "d = len(e01tr) + len(e02tr) + len(e03tr)\n",
    "print(d)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "print(val_x.shape)\n",
    "print(val_y.shape)\n",
    "\n",
    "\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 68, 8)             24        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 68, 16)            144       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 68, 32)            544       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 68, 64)            2112      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 68, 32)            2080      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 68, 16)            528       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 68, 8)             136       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 544)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 3)                 1635      \n",
      "=================================================================\n",
      "Total params: 7,203\n",
      "Trainable params: 7,203\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26515 samples, validate on 3708 samples\n",
      "Epoch 1/50\n",
      "26515/26515 [==============================] - 4s 159us/step - loss: 0.8040 - acc: 0.6396 - val_loss: 0.4789 - val_acc: 0.8207\n",
      "Epoch 2/50\n",
      "26515/26515 [==============================] - 4s 147us/step - loss: 0.4758 - acc: 0.8138 - val_loss: 0.3827 - val_acc: 0.8492\n",
      "Epoch 3/50\n",
      "26515/26515 [==============================] - 4s 147us/step - loss: 0.4150 - acc: 0.8408 - val_loss: 0.3474 - val_acc: 0.8714\n",
      "Epoch 4/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3995 - acc: 0.8477 - val_loss: 0.3498 - val_acc: 0.8662\n",
      "Epoch 5/50\n",
      "26515/26515 [==============================] - 4s 147us/step - loss: 0.3811 - acc: 0.8563 - val_loss: 0.3407 - val_acc: 0.8687\n",
      "Epoch 6/50\n",
      "26515/26515 [==============================] - 4s 147us/step - loss: 0.3673 - acc: 0.8624 - val_loss: 0.3275 - val_acc: 0.8708\n",
      "Epoch 7/50\n",
      "26515/26515 [==============================] - 4s 149us/step - loss: 0.3644 - acc: 0.8630 - val_loss: 0.3242 - val_acc: 0.8803\n",
      "Epoch 8/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3641 - acc: 0.8627 - val_loss: 0.3376 - val_acc: 0.8670\n",
      "Epoch 9/50\n",
      "26515/26515 [==============================] - 4s 150us/step - loss: 0.3556 - acc: 0.8674 - val_loss: 0.3285 - val_acc: 0.8784\n",
      "Epoch 10/50\n",
      "26515/26515 [==============================] - 4s 150us/step - loss: 0.3531 - acc: 0.8693 - val_loss: 0.3398 - val_acc: 0.8679\n",
      "Epoch 11/50\n",
      "26515/26515 [==============================] - 4s 149us/step - loss: 0.3504 - acc: 0.8711 - val_loss: 0.2951 - val_acc: 0.8913\n",
      "Epoch 12/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3494 - acc: 0.8697 - val_loss: 0.3328 - val_acc: 0.8679\n",
      "Epoch 13/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3443 - acc: 0.8737 - val_loss: 0.3020 - val_acc: 0.8881\n",
      "Epoch 14/50\n",
      "26515/26515 [==============================] - 4s 147us/step - loss: 0.3440 - acc: 0.8726 - val_loss: 0.3149 - val_acc: 0.8792\n",
      "Epoch 15/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3445 - acc: 0.8721 - val_loss: 0.3079 - val_acc: 0.8819\n",
      "Epoch 16/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3331 - acc: 0.8777 - val_loss: 0.3420 - val_acc: 0.8662\n",
      "Epoch 17/50\n",
      "26515/26515 [==============================] - 4s 147us/step - loss: 0.3398 - acc: 0.8757 - val_loss: 0.3226 - val_acc: 0.8724\n",
      "Epoch 18/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3361 - acc: 0.8763 - val_loss: 0.3040 - val_acc: 0.8797\n",
      "Epoch 19/50\n",
      "26515/26515 [==============================] - 4s 147us/step - loss: 0.3297 - acc: 0.8812 - val_loss: 0.2839 - val_acc: 0.8986\n",
      "Epoch 20/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3326 - acc: 0.8777 - val_loss: 0.3055 - val_acc: 0.8827\n",
      "Epoch 21/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3328 - acc: 0.8770 - val_loss: 0.3108 - val_acc: 0.8781\n",
      "Epoch 22/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3244 - acc: 0.8823 - val_loss: 0.2951 - val_acc: 0.8873\n",
      "Epoch 23/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3258 - acc: 0.8809 - val_loss: 0.2829 - val_acc: 0.8951\n",
      "Epoch 24/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3269 - acc: 0.8819 - val_loss: 0.3074 - val_acc: 0.8797\n",
      "Epoch 25/50\n",
      "26515/26515 [==============================] - 4s 147us/step - loss: 0.3231 - acc: 0.8805 - val_loss: 0.2899 - val_acc: 0.8873\n",
      "Epoch 26/50\n",
      "26515/26515 [==============================] - 4s 147us/step - loss: 0.3281 - acc: 0.8798 - val_loss: 0.3188 - val_acc: 0.8754\n",
      "Epoch 27/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3238 - acc: 0.8807 - val_loss: 0.2683 - val_acc: 0.9024\n",
      "Epoch 28/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3208 - acc: 0.8834 - val_loss: 0.2799 - val_acc: 0.8964\n",
      "Epoch 29/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3205 - acc: 0.8843 - val_loss: 0.3136 - val_acc: 0.8786\n",
      "Epoch 30/50\n",
      "26515/26515 [==============================] - 4s 147us/step - loss: 0.3157 - acc: 0.8855 - val_loss: 0.2731 - val_acc: 0.8954\n",
      "Epoch 31/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3215 - acc: 0.8828 - val_loss: 0.2813 - val_acc: 0.8935\n",
      "Epoch 32/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3177 - acc: 0.8830 - val_loss: 0.3142 - val_acc: 0.8757\n",
      "Epoch 33/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3167 - acc: 0.8840 - val_loss: 0.2727 - val_acc: 0.8962\n",
      "Epoch 34/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3160 - acc: 0.8847 - val_loss: 0.2768 - val_acc: 0.9048\n",
      "Epoch 35/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3128 - acc: 0.8875 - val_loss: 0.2738 - val_acc: 0.8975\n",
      "Epoch 36/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3212 - acc: 0.8821 - val_loss: 0.2672 - val_acc: 0.9045\n",
      "Epoch 37/50\n",
      "26515/26515 [==============================] - 4s 147us/step - loss: 0.3195 - acc: 0.8843 - val_loss: 0.2769 - val_acc: 0.8970\n",
      "Epoch 38/50\n",
      "26515/26515 [==============================] - 4s 147us/step - loss: 0.3174 - acc: 0.8835 - val_loss: 0.2906 - val_acc: 0.8875\n",
      "Epoch 39/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3089 - acc: 0.8883 - val_loss: 0.2876 - val_acc: 0.8910\n",
      "Epoch 40/50\n",
      "26515/26515 [==============================] - 4s 149us/step - loss: 0.3180 - acc: 0.8837 - val_loss: 0.2800 - val_acc: 0.8921\n",
      "Epoch 41/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3072 - acc: 0.8889 - val_loss: 0.2887 - val_acc: 0.8913\n",
      "Epoch 42/50\n",
      "26515/26515 [==============================] - 4s 147us/step - loss: 0.3076 - acc: 0.8886 - val_loss: 0.2790 - val_acc: 0.8975\n",
      "Epoch 43/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3185 - acc: 0.8818 - val_loss: 0.3001 - val_acc: 0.8897\n",
      "Epoch 44/50\n",
      "26515/26515 [==============================] - 4s 147us/step - loss: 0.3105 - acc: 0.8855 - val_loss: 0.2737 - val_acc: 0.8967\n",
      "Epoch 45/50\n",
      "26515/26515 [==============================] - 4s 147us/step - loss: 0.3044 - acc: 0.8898 - val_loss: 0.2724 - val_acc: 0.8932\n",
      "Epoch 46/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3074 - acc: 0.8876 - val_loss: 0.2739 - val_acc: 0.8972\n",
      "Epoch 47/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3110 - acc: 0.8866 - val_loss: 0.2586 - val_acc: 0.9026\n",
      "Epoch 48/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3052 - acc: 0.8892 - val_loss: 0.2692 - val_acc: 0.9032\n",
      "Epoch 49/50\n",
      "26515/26515 [==============================] - 4s 147us/step - loss: 0.3092 - acc: 0.8861 - val_loss: 0.2873 - val_acc: 0.8878\n",
      "Epoch 50/50\n",
      "26515/26515 [==============================] - 4s 148us/step - loss: 0.3097 - acc: 0.8862 - val_loss: 0.2661 - val_acc: 0.9026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0dbb795dd8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(8 , activation='relu', input_shape=(68,2)))\n",
    "model.add(Dense(16 , activation='relu'))\n",
    "model.add(Dense(32 , activation='relu'))\n",
    "model.add(Dense(64 , activation='relu'))\n",
    "model.add(Dense(128 , activation='relu'))\n",
    "model.add(Dense(256 , activation='relu'))\n",
    "model.add(Dense(128 , activation='relu'))\n",
    "model.add(Dense(64 , activation='relu'))\n",
    "model.add(Dense(32 , activation='relu'))\n",
    "model.add(Dense(16 , activation='relu'))\n",
    "model.add(Dense(8 , activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(Dense(3 , activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x, train_y, batch_size=100, epochs=50, validation_data=(val_x, val_y), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3678/3678 [==============================] - 0s 80us/step\n",
      "[0.31558841879339306, 0.8814573135630083]\n"
     ]
    }
   ],
   "source": [
    "acc = model.evaluate(test_x, test_y)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"dlib_face_entire.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.array(list_pointslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2 = k.reshape(-1, 68, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_points6 = np.array(list_points5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(k2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shape.parts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=100, epochs=20, validation_split=0.2, callbacks=[earlystopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
