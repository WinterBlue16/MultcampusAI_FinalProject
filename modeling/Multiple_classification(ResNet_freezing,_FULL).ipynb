{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J9PWadNLDx9t"
   },
   "outputs": [],
   "source": [
    "# !unzip -uq \"/content/drive/My Drive/roi.zip\" -d \"/content/drive/My Drive/roi_sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2QLiM-BKD5l"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten,  GlobalAveragePooling2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "P_hgSH91KYAv",
    "outputId": "dfc72cfe-bad7-4efb-c464-fde15abd5205"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero 경로에 저장된 파일의 개수:2880\n",
      "plus 경로에 저장된 파일의 개수:2880\n",
      "minus 경로에 저장된 파일의 개수:2880\n"
     ]
    }
   ],
   "source": [
    "path_plus='roi_sample/E01' # 무표정\n",
    "path_zero='roi_sample/E02' # 웃음\n",
    "path_minus='roi_sample/E03' # 찡그림\n",
    "# path_unkno='image/unknown'\n",
    "\n",
    "la=len(os.listdir(path_zero))\n",
    "lb=len(os.listdir(path_plus))\n",
    "lc=len(os.listdir(path_minus))\n",
    "# lc=len(os.listdir(path_unkno)) \n",
    "\n",
    "print('zero 경로에 저장된 파일의 개수:'+str(la))\n",
    "print('plus 경로에 저장된 파일의 개수:'+str(lb))\n",
    "print('minus 경로에 저장된 파일의 개수:'+str(lc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nMQmzc5pLH65"
   },
   "outputs": [],
   "source": [
    "xsize=100\n",
    "ysize=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n09d4btxLtti"
   },
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "def read_dir(path, label):\n",
    "    \n",
    "    files = glob.glob(path + \"/*.jpg\")\n",
    "    if bool(files) == False:\n",
    "        files = glob.glob(path + \"/*.png\") \n",
    "     \n",
    "    for f in files:\n",
    "\n",
    "        try:\n",
    "            img = image.load_img(f, target_size=(xsize,ysize))\n",
    "            img_tr= image.img_to_array(img)        \n",
    "            img_tr /= 255.\n",
    "            \n",
    "            y.append(label)\n",
    "            x.append(img_tr)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KL-ucbH1L5Wc"
   },
   "outputs": [],
   "source": [
    "read_dir(path_zero, 0) #'plus emotion')\n",
    "read_dir(path_plus, 1) #'zero emotion')\n",
    "read_dir(path_minus, 2) #'minus emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4gi6jWhsMKbU"
   },
   "outputs": [],
   "source": [
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XdV3CnMvM21M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8640, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_beqHoaCMQ6J"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "\n",
    "input_shape = (xsize,ysize, 3)\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 2\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Co6u22N1MpmJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(864, 100, 100, 3)\n",
      "(864,)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yau5rgOQOz9s"
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 613
    },
    "colab_type": "code",
    "id": "poHl5czmPBL1",
    "outputId": "b28aab06-35a6-414c-8d4b-92a2f8b88129"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.applications import ResNet50, ResNet101 \n",
    "\n",
    "input_shape = (100, 100, 3)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "base_model.trainable=False\n",
    "\n",
    "x = Flatten()(base_model.output)\n",
    "output = Dense(3, activation='softmax', name='predictions')(x)\n",
    "model = Model(inputs=base_model.input, output=output)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 793
    },
    "colab_type": "code",
    "id": "uJTed-KsPQ2r",
    "outputId": "86121350-c920-4a08-924e-8e4577ec58be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 6220 samples, validate on 1556 samples\n",
      "Epoch 1/30\n",
      "6220/6220 [==============================] - 36s 6ms/step - loss: 1.2124 - accuracy: 0.7870 - val_loss: 15612.2429 - val_accuracy: 0.3560\n",
      "Epoch 2/30\n",
      "6220/6220 [==============================] - 20s 3ms/step - loss: 0.0661 - accuracy: 0.9744 - val_loss: 1.1681 - val_accuracy: 0.3445\n",
      "Epoch 3/30\n",
      "6220/6220 [==============================] - 20s 3ms/step - loss: 0.0260 - accuracy: 0.9912 - val_loss: 1.1254 - val_accuracy: 0.2995\n",
      "Epoch 4/30\n",
      "6220/6220 [==============================] - 21s 3ms/step - loss: 0.0157 - accuracy: 0.9942 - val_loss: 1.1009 - val_accuracy: 0.2995\n",
      "Epoch 5/30\n",
      "6220/6220 [==============================] - 21s 3ms/step - loss: 0.0260 - accuracy: 0.9915 - val_loss: 1.0997 - val_accuracy: 0.3066\n",
      "Epoch 6/30\n",
      "6220/6220 [==============================] - 21s 3ms/step - loss: 0.0249 - accuracy: 0.9931 - val_loss: 1.1000 - val_accuracy: 0.3014\n",
      "Epoch 7/30\n",
      "6220/6220 [==============================] - 21s 3ms/step - loss: 0.0589 - accuracy: 0.9805 - val_loss: 1.0969 - val_accuracy: 0.3188\n",
      "Epoch 8/30\n",
      "6220/6220 [==============================] - 21s 3ms/step - loss: 0.0212 - accuracy: 0.9944 - val_loss: 1.0822 - val_accuracy: 0.4190\n",
      "Epoch 9/30\n",
      "6220/6220 [==============================] - 21s 3ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 1.2985 - val_accuracy: 0.3593\n",
      "Epoch 10/30\n",
      "6220/6220 [==============================] - 22s 3ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 1.2136 - val_accuracy: 0.4621\n",
      "Epoch 11/30\n",
      "6220/6220 [==============================] - 22s 3ms/step - loss: 0.0176 - accuracy: 0.9936 - val_loss: 0.7359 - val_accuracy: 0.7641\n",
      "Epoch 12/30\n",
      "6220/6220 [==============================] - 22s 3ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.9542 - val_accuracy: 0.7397\n",
      "Epoch 13/30\n",
      "6220/6220 [==============================] - 22s 3ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 1.4440 - val_accuracy: 0.7487\n",
      "Epoch 14/30\n",
      "6220/6220 [==============================] - 22s 3ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.2082 - val_accuracy: 0.9402\n",
      "Epoch 15/30\n",
      "6220/6220 [==============================] - 22s 3ms/step - loss: 4.3468e-04 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9621\n",
      "Epoch 16/30\n",
      "6220/6220 [==============================] - 22s 3ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.0872 - val_accuracy: 0.9692\n",
      "Epoch 17/30\n",
      "6220/6220 [==============================] - 22s 3ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.0530 - val_accuracy: 0.9820\n",
      "Epoch 18/30\n",
      "6220/6220 [==============================] - 22s 3ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0479 - val_accuracy: 0.9891\n",
      "Epoch 19/30\n",
      "6220/6220 [==============================] - 22s 3ms/step - loss: 2.1826e-04 - accuracy: 0.9998 - val_loss: 0.0062 - val_accuracy: 0.9968\n",
      "Epoch 20/30\n",
      "6220/6220 [==============================] - 22s 3ms/step - loss: 6.0743e-05 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9981\n",
      "Epoch 21/30\n",
      "6220/6220 [==============================] - 22s 3ms/step - loss: 3.1616e-05 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9987\n",
      "Epoch 22/30\n",
      "6220/6220 [==============================] - 22s 3ms/step - loss: 4.4916e-05 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
      "Epoch 23/30\n",
      "6220/6220 [==============================] - 22s 3ms/step - loss: 1.1049e-05 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9987\n",
      "Epoch 24/30\n",
      "6220/6220 [==============================] - 22s 3ms/step - loss: 9.1798e-06 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9987\n",
      "Epoch 25/30\n",
      "6220/6220 [==============================] - 22s 3ms/step - loss: 1.1437e-05 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9987\n",
      "Epoch 26/30\n",
      "6220/6220 [==============================] - 22s 3ms/step - loss: 6.9839e-06 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9987\n",
      "Epoch 27/30\n",
      "6220/6220 [==============================] - 22s 3ms/step - loss: 5.6196e-06 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9987\n",
      "Epoch 28/30\n",
      "6220/6220 [==============================] - 22s 3ms/step - loss: 5.5769e-06 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9987\n",
      "Epoch 29/30\n",
      "6220/6220 [==============================] - 22s 3ms/step - loss: 5.0701e-06 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9987\n",
      "Epoch 30/30\n",
      "6220/6220 [==============================] - 22s 3ms/step - loss: 4.0396e-06 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9987\n",
      "864/864 [==============================] - 2s 2ms/step\n",
      "[0.003396477615360072, 0.9988425970077515]\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_split=0.2, \n",
    "          epochs=30, batch_size=100, verbose=1)\n",
    "\n",
    "acc = model.evaluate(x_test, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('save/ResNet_freezing(full).h5')\n",
    "print('모델 저장이 완료되었습니다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nVddSc6nQeND"
   },
   "outputs": [],
   "source": [
    "test_path = \"test_dataset/Happy/Happy\" # 기쁨만 모인 test set\n",
    "test_path2 = \"test_dataset/Neutral/Neutral\" # 무표정만 모인 test set \n",
    "\n",
    "X=[]\n",
    "\n",
    "def read_dir1(path):\n",
    "    \n",
    "    files = glob.glob(path + \"/*.jpg\")\n",
    "    if bool(files) == False:\n",
    "        files = glob.glob(path + \"/*.png\") \n",
    "     \n",
    "    for f in files:\n",
    "\n",
    "        try:\n",
    "            img = image.load_img(f, target_size=(xsize,ysize))\n",
    "            img_tr= image.img_to_array(img)        \n",
    "            img_tr /= 255.\n",
    "            X.append(img_tr)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-uzScQd3be-h",
    "outputId": "9ae320d9-f05f-4c17-b8c4-491918f53210",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test set 기쁨\n",
    "read_dir1(test_path)\n",
    "X = np.array(X)\n",
    "pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L7whqfq-fHpt"
   },
   "outputs": [],
   "source": [
    "# test set(무표정)\n",
    "read_dir1(test_path2)\n",
    "X = np.array(X)\n",
    "pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "bAPwPmZPcJoU",
    "outputId": "74a70d9b-8466-47a1-c450-6fbebcb136a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00020201000000000000002000000000000200000000200020000000000000002000000002000000200000001020200000002000000200002002000000020000100000000000022020000020000000000020020222002000000000000000000200000000\n",
      " 0.015\n"
     ]
    }
   ],
   "source": [
    "# 예측(test set 기쁨)\n",
    "co=0\n",
    "for i in range(200):\n",
    "    print(np.argmax(pred[i]),end='')\n",
    "    tmp=np.argmax(pred[i])\n",
    "    \n",
    "    if tmp == 1:\n",
    "        co+=1\n",
    "\n",
    "print('\\n',co/200.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "Y2jnzovrdp9d",
    "outputId": "5c3de284-7ee3-4e33-f227-84bf7361b53a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00020201000000000000002000000000000200000000200020000000000000002000000002000000200000001020200000002000000200002002000000020000100000000000022020000020000000000020020222002000000000000000000200000000\n",
      " 0.85\n"
     ]
    }
   ],
   "source": [
    "# 예측(test set 무표정)\n",
    "co=0\n",
    "for i in range(200):\n",
    "    print(np.argmax(pred[i]),end='')\n",
    "    tmp=np.argmax(pred[i])\n",
    "    \n",
    "    if tmp == 0:\n",
    "        co+=1\n",
    "\n",
    "print('\\n',co/200.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pqsfX7LKhqyj"
   },
   "outputs": [],
   "source": [
    "# 기쁨 예측 정확도 : 1.5 %\n",
    "# 무표정 예측 정확도 : 85 %\n",
    "\n",
    "# 역시 무표정 예측 정확도가 더 높음 \n",
    "# 데이터 증식이나 모델 파라미터 조정이 필요함(50 % 이상 목표)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Multiple classification(DenseNet, FULL)2",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:amazonei_tensorflow_p36]",
   "language": "python",
   "name": "conda-env-amazonei_tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
