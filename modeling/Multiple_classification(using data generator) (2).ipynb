{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip -uq \"dataset_imageprocessing.zip\" -d \"dataset_imageprocessing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers import Reshape, Permute, Activation, Input, merge\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import cv2, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sessions = tf. Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras_applications/mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 400, 400, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)       (None, 401, 401, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 200, 200, 32) 864         Conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 200, 200, 32) 128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 200, 200, 32) 0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 200, 200, 32) 288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 200, 200, 32) 128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 200, 200, 32) 0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 200, 200, 16) 512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 200, 200, 16) 64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 200, 200, 96) 1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 200, 200, 96) 384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 200, 200, 96) 0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 201, 201, 96) 0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 100, 100, 96) 864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 100, 100, 96) 384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 100, 100, 96) 0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 100, 100, 24) 2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 100, 100, 24) 96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 100, 100, 144 3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 100, 100, 144 576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 100, 100, 144 0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 100, 100, 144 1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 100, 100, 144 576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 100, 100, 144 0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 100, 100, 24) 3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 100, 100, 24) 96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 100, 100, 24) 0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 100, 100, 144 3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 100, 100, 144 576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 100, 100, 144 0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 101, 101, 144 0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 50, 50, 144)  1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 50, 50, 144)  576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 50, 50, 144)  0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 50, 50, 32)   4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 50, 50, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 50, 50, 192)  6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 50, 50, 192)  768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 50, 50, 192)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 50, 50, 192)  1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 50, 50, 192)  768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 50, 50, 192)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 50, 50, 32)   6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 50, 50, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 50, 50, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 50, 50, 192)  6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 50, 50, 192)  768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 50, 50, 192)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 50, 50, 192)  1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 50, 50, 192)  768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 50, 50, 192)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 50, 50, 32)   6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 50, 50, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 50, 50, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 50, 50, 192)  6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 50, 50, 192)  768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 50, 50, 192)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 51, 51, 192)  0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 25, 25, 192)  1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 25, 25, 192)  768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 25, 25, 192)  0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 25, 25, 64)   12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 25, 25, 64)   256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 25, 25, 384)  24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 25, 25, 384)  1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 25, 25, 384)  0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 25, 25, 384)  3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 25, 25, 384)  1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 25, 25, 384)  0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 25, 25, 64)   24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 25, 25, 64)   256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 25, 25, 64)   0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 25, 25, 384)  24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 25, 25, 384)  1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 25, 25, 384)  0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 25, 25, 384)  3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 25, 25, 384)  1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 25, 25, 384)  0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 25, 25, 64)   24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 25, 25, 64)   256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 25, 25, 64)   0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 25, 25, 384)  24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 25, 25, 384)  1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 25, 25, 384)  0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 25, 25, 384)  3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 25, 25, 384)  1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 25, 25, 384)  0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 25, 25, 64)   24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 25, 25, 64)   256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 25, 25, 64)   0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 25, 25, 384)  24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 25, 25, 384)  1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 25, 25, 384)  0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 25, 25, 384)  3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 25, 25, 384)  1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 25, 25, 384)  0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 25, 25, 96)   36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 25, 25, 96)   384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 25, 25, 576)  55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 25, 25, 576)  2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 25, 25, 576)  0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 25, 25, 576)  5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 25, 25, 576)  2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 25, 25, 576)  0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 25, 25, 96)   55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 25, 25, 96)   384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 25, 25, 96)   0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 25, 25, 576)  55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 25, 25, 576)  2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 25, 25, 576)  0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 25, 25, 576)  5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 25, 25, 576)  2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 25, 25, 576)  0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 25, 25, 96)   55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 25, 25, 96)   384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 25, 25, 96)   0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 25, 25, 576)  55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 25, 25, 576)  2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 25, 25, 576)  0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 27, 27, 576)  0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 13, 13, 576)  5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 13, 13, 576)  2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 13, 13, 576)  0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 13, 13, 160)  92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 13, 13, 160)  640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 13, 13, 960)  153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 13, 13, 960)  3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 13, 13, 960)  0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 13, 13, 960)  8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 13, 13, 960)  3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 13, 13, 960)  0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 13, 13, 160)  153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 13, 13, 160)  640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 13, 13, 160)  0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 13, 13, 960)  153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 13, 13, 960)  3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 13, 13, 960)  0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 13, 13, 960)  8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 13, 13, 960)  3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 13, 13, 960)  0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 13, 13, 160)  153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 13, 13, 160)  640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 13, 13, 160)  0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 13, 13, 960)  153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 13, 13, 960)  3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 13, 13, 960)  0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 13, 13, 960)  8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 13, 13, 960)  3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 13, 13, 960)  0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 13, 13, 320)  307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 13, 13, 320)  1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 13, 13, 1280) 409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 13, 13, 1280) 5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 13, 13, 1280) 0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 216320)       0           out_relu[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 216320)       0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 3)            648963      dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,906,947\n",
      "Trainable params: 648,963\n",
      "Non-trainable params: 2,257,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n"
     ]
    }
   ],
   "source": [
    "# Transfer learning(MobileNetV2)\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2  \n",
    "from keras.applications.mobilenet import MobileNet\n",
    "\n",
    "input_shape = (400, 400, 3)\n",
    "# base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "# 미세 조정\n",
    "base_model.trainable=True\n",
    "\n",
    "set_trainable=False\n",
    "for layer in base_model.layers:\n",
    "    if layer.name == 'out_relu': # 쌓은 층 직전까지 동결\n",
    "        set_trainable=True\n",
    "    if set_trainable:\n",
    "        layer.trainable=True\n",
    "    else:\n",
    "        layer.trainable=False\n",
    "\n",
    "\n",
    "x = Flatten()(base_model.output)\n",
    "# x = Dense(256, activation='relu')(x)\n",
    "dropout = Dropout(0.6)(x)\n",
    "output = Dense(3, activation='softmax', name='predictions')(dropout)\n",
    "model = Model(inputs=base_model.input, output=output)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 400, 400, 64)      1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 400, 400, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 400, 400, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 200, 200, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 200, 200, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 200, 200, 128)     204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 200, 200, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 200, 200, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 100, 100, 128)     0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100, 100, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 100, 100, 512)     590336    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 100, 100, 512)     2048      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 100, 100, 512)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 50, 50, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50, 50, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 50, 50, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 50, 50, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 50, 50, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 25, 25, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 25, 25, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 320000)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               81920256  \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 85,218,179\n",
      "Trainable params: 85,214,211\n",
      "Non-trainable params: 3,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CNN model\n",
    "# cnn2\n",
    "\n",
    "from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# number of possible label values\n",
    "nb_classes = 3\n",
    "\n",
    "# Initialising the CNN\n",
    "model = Sequential()\n",
    "\n",
    "# 1 - Convolution\n",
    "model.add(Conv2D(64,(3,3), padding='same', input_shape=(400, 400, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 2nd Convolution layer\n",
    "model.add(Conv2D(128,(5,5), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 3rd Convolution layer\n",
    "model.add(Conv2D(512,(3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 4th Convolution layer\n",
    "model.add(Conv2D(512,(3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flattening\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer 1st layer\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Fully connected layer 2nd layer\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "opt = Adam(lr=0.0001)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35144 images belonging to 3 classes.\n",
      "Found 8785 images belonging to 3 classes.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/50\n",
      "128/128 [==============================] - 61s 478ms/step - loss: 5.9366 - accuracy: 0.6934 - val_loss: 28.0733 - val_accuracy: 0.4891\n",
      "Epoch 2/50\n",
      "128/128 [==============================] - 56s 438ms/step - loss: 4.9670 - accuracy: 0.7832 - val_loss: 0.0000e+00 - val_accuracy: 0.4813\n",
      "Epoch 3/50\n",
      "128/128 [==============================] - 57s 444ms/step - loss: 4.5003 - accuracy: 0.8179 - val_loss: 38.3309 - val_accuracy: 0.4557\n",
      "Epoch 4/50\n",
      "128/128 [==============================] - 57s 445ms/step - loss: 4.7413 - accuracy: 0.8389 - val_loss: 5.6260 - val_accuracy: 0.5713\n",
      "Epoch 5/50\n",
      "128/128 [==============================] - 57s 442ms/step - loss: 4.8218 - accuracy: 0.8545 - val_loss: 0.0000e+00 - val_accuracy: 0.5614\n",
      "Epoch 6/50\n",
      "128/128 [==============================] - 56s 441ms/step - loss: 5.1666 - accuracy: 0.8555 - val_loss: 0.0000e+00 - val_accuracy: 0.5588\n",
      "Epoch 7/50\n",
      "128/128 [==============================] - 57s 444ms/step - loss: 4.9392 - accuracy: 0.8589 - val_loss: 0.0000e+00 - val_accuracy: 0.4403\n",
      "Epoch 8/50\n",
      "128/128 [==============================] - 57s 446ms/step - loss: 5.5604 - accuracy: 0.8652 - val_loss: 16.0419 - val_accuracy: 0.6099\n",
      "Epoch 9/50\n",
      "128/128 [==============================] - 57s 446ms/step - loss: 5.4259 - accuracy: 0.8691 - val_loss: 0.0000e+00 - val_accuracy: 0.5517\n",
      "Epoch 10/50\n",
      "128/128 [==============================] - 58s 455ms/step - loss: 5.8094 - accuracy: 0.8647 - val_loss: 0.0000e+00 - val_accuracy: 0.6060\n",
      "Epoch 11/50\n",
      "128/128 [==============================] - 57s 444ms/step - loss: 5.3694 - accuracy: 0.8726 - val_loss: 1.4679 - val_accuracy: 0.5135\n",
      "Epoch 12/50\n",
      "128/128 [==============================] - 58s 450ms/step - loss: 6.2293 - accuracy: 0.8745 - val_loss: 24.8487 - val_accuracy: 0.4855\n",
      "Epoch 13/50\n",
      "128/128 [==============================] - 57s 447ms/step - loss: 6.5370 - accuracy: 0.8735 - val_loss: 31.7899 - val_accuracy: 0.6112\n",
      "Epoch 14/50\n",
      "128/128 [==============================] - 57s 444ms/step - loss: 5.0932 - accuracy: 0.8896 - val_loss: 0.0000e+00 - val_accuracy: 0.6548\n",
      "Epoch 15/50\n",
      "128/128 [==============================] - 57s 446ms/step - loss: 5.9280 - accuracy: 0.8848 - val_loss: 56.7938 - val_accuracy: 0.6472\n",
      "Epoch 16/50\n",
      "128/128 [==============================] - 58s 449ms/step - loss: 5.7543 - accuracy: 0.8931 - val_loss: 68.3952 - val_accuracy: 0.6455\n",
      "Epoch 17/50\n",
      "128/128 [==============================] - 59s 458ms/step - loss: 5.7096 - accuracy: 0.8931 - val_loss: 107.6796 - val_accuracy: 0.5269\n",
      "Epoch 18/50\n",
      "128/128 [==============================] - 60s 470ms/step - loss: 3.7631 - accuracy: 0.9160 - val_loss: 72.6263 - val_accuracy: 0.6818\n",
      "Epoch 19/50\n",
      "128/128 [==============================] - 60s 468ms/step - loss: 3.1536 - accuracy: 0.9287 - val_loss: 0.0000e+00 - val_accuracy: 0.6919\n",
      "Epoch 20/50\n",
      "128/128 [==============================] - 60s 468ms/step - loss: 3.2570 - accuracy: 0.9336 - val_loss: 0.0000e+00 - val_accuracy: 0.6782\n",
      "Epoch 21/50\n",
      "128/128 [==============================] - 60s 469ms/step - loss: 4.9812 - accuracy: 0.9092 - val_loss: 0.0000e+00 - val_accuracy: 0.7207\n",
      "Epoch 22/50\n",
      "128/128 [==============================] - 60s 469ms/step - loss: 3.5771 - accuracy: 0.9258 - val_loss: 28.0384 - val_accuracy: 0.6758\n",
      "Epoch 23/50\n",
      "128/128 [==============================] - 60s 470ms/step - loss: 4.4648 - accuracy: 0.9106 - val_loss: 0.0000e+00 - val_accuracy: 0.7009\n",
      "Epoch 24/50\n",
      "128/128 [==============================] - 60s 470ms/step - loss: 4.1214 - accuracy: 0.9199 - val_loss: 0.1443 - val_accuracy: 0.6608\n",
      "Epoch 25/50\n",
      "128/128 [==============================] - 60s 466ms/step - loss: 5.1941 - accuracy: 0.9131 - val_loss: 0.0000e+00 - val_accuracy: 0.7243\n",
      "Epoch 26/50\n",
      "128/128 [==============================] - 60s 469ms/step - loss: 4.6587 - accuracy: 0.9204 - val_loss: 0.0000e+00 - val_accuracy: 0.7166\n",
      "Epoch 27/50\n",
      "128/128 [==============================] - 60s 468ms/step - loss: 4.3208 - accuracy: 0.9277 - val_loss: 2.3842e-07 - val_accuracy: 0.6982\n",
      "Epoch 28/50\n",
      "128/128 [==============================] - 60s 466ms/step - loss: 4.0829 - accuracy: 0.9233 - val_loss: 114.7745 - val_accuracy: 0.6521\n",
      "Epoch 29/50\n",
      "128/128 [==============================] - 59s 465ms/step - loss: 5.1946 - accuracy: 0.9121 - val_loss: 0.0000e+00 - val_accuracy: 0.7249\n",
      "Epoch 30/50\n",
      "128/128 [==============================] - 60s 471ms/step - loss: 5.3674 - accuracy: 0.9141 - val_loss: 0.0000e+00 - val_accuracy: 0.6733\n",
      "Epoch 31/50\n",
      "128/128 [==============================] - 57s 447ms/step - loss: 6.6773 - accuracy: 0.9034 - val_loss: 0.0000e+00 - val_accuracy: 0.6373\n",
      "Epoch 32/50\n",
      "128/128 [==============================] - 57s 446ms/step - loss: 5.2346 - accuracy: 0.9160 - val_loss: 85.2001 - val_accuracy: 0.6735\n",
      "Epoch 33/50\n",
      "128/128 [==============================] - 57s 449ms/step - loss: 4.9296 - accuracy: 0.9189 - val_loss: 46.2046 - val_accuracy: 0.7045\n",
      "Epoch 34/50\n",
      "128/128 [==============================] - 57s 448ms/step - loss: 5.1262 - accuracy: 0.9150 - val_loss: 6.2589e-04 - val_accuracy: 0.7180\n",
      "Epoch 35/50\n",
      "128/128 [==============================] - 57s 445ms/step - loss: 3.4932 - accuracy: 0.9404 - val_loss: 0.0029 - val_accuracy: 0.6451\n",
      "Epoch 36/50\n",
      "128/128 [==============================] - 60s 466ms/step - loss: 3.2722 - accuracy: 0.9424 - val_loss: 2.2766e-04 - val_accuracy: 0.6627\n",
      "Epoch 37/50\n",
      "128/128 [==============================] - 60s 472ms/step - loss: 4.0424 - accuracy: 0.9370 - val_loss: 0.0000e+00 - val_accuracy: 0.6724\n",
      "Epoch 38/50\n",
      "128/128 [==============================] - 61s 473ms/step - loss: 4.3600 - accuracy: 0.9336 - val_loss: 44.4387 - val_accuracy: 0.6686\n",
      "Epoch 39/50\n",
      "128/128 [==============================] - 60s 467ms/step - loss: 4.8990 - accuracy: 0.9243 - val_loss: 0.0000e+00 - val_accuracy: 0.6925\n",
      "Epoch 40/50\n",
      "128/128 [==============================] - 61s 479ms/step - loss: 4.7653 - accuracy: 0.9292 - val_loss: 44.3064 - val_accuracy: 0.6862\n",
      "Epoch 41/50\n",
      "128/128 [==============================] - 60s 470ms/step - loss: 4.2017 - accuracy: 0.9429 - val_loss: 9.6179e-04 - val_accuracy: 0.6674\n",
      "Epoch 42/50\n",
      "128/128 [==============================] - 61s 474ms/step - loss: 3.4453 - accuracy: 0.9485 - val_loss: 0.0091 - val_accuracy: 0.6681\n",
      "Epoch 43/50\n",
      "128/128 [==============================] - 60s 469ms/step - loss: 3.9194 - accuracy: 0.9370 - val_loss: 0.0000e+00 - val_accuracy: 0.6469\n",
      "Epoch 44/50\n",
      "128/128 [==============================] - 60s 473ms/step - loss: 3.9005 - accuracy: 0.9409 - val_loss: 33.8609 - val_accuracy: 0.6064\n",
      "Epoch 45/50\n",
      "128/128 [==============================] - 60s 470ms/step - loss: 5.1217 - accuracy: 0.9287 - val_loss: 0.0000e+00 - val_accuracy: 0.6591\n",
      "Epoch 46/50\n",
      "128/128 [==============================] - 60s 469ms/step - loss: 3.9238 - accuracy: 0.9463 - val_loss: 0.0000e+00 - val_accuracy: 0.6015\n",
      "Epoch 47/50\n",
      "128/128 [==============================] - 60s 468ms/step - loss: 3.7690 - accuracy: 0.9380 - val_loss: 0.0000e+00 - val_accuracy: 0.6495\n",
      "Epoch 48/50\n",
      "128/128 [==============================] - 60s 470ms/step - loss: 5.8357 - accuracy: 0.9219 - val_loss: 0.0000e+00 - val_accuracy: 0.7056\n",
      "Epoch 49/50\n",
      "128/128 [==============================] - 60s 469ms/step - loss: 4.3100 - accuracy: 0.9443 - val_loss: 0.0000e+00 - val_accuracy: 0.6453\n",
      "Epoch 50/50\n",
      "128/128 [==============================] - 60s 467ms/step - loss: 5.0098 - accuracy: 0.9287 - val_loss: 100.5964 - val_accuracy: 0.6910\n"
     ]
    }
   ],
   "source": [
    "# ImagedataGenerator 불러오기\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# train data load \n",
    "train_set = train_datagen.flow_from_directory('dataset_imageprocessing/dataset_imageprocessing/train/', \n",
    "                                              target_size=(400, 400), # 400, 400 \n",
    "                                              class_mode='categorical', \n",
    "                                              batch_size=16)\n",
    "\n",
    "# val data load \n",
    "test_set = test_datagen.flow_from_directory('dataset_imageprocessing/dataset_imageprocessing/test/', \n",
    "                                            target_size=(400, 400), # 400, 400\n",
    "                                            class_mode='categorical', \n",
    "                                            batch_size=16) # suffle 적용/적용하지 않기\n",
    "\n",
    "# fit model\n",
    "history = model.fit_generator(train_set,\n",
    "                              epochs = 50,\n",
    "                              steps_per_epoch=128,\n",
    "                             validation_data = test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'E01': 0, 'E02': 1, 'E03': 2}\n"
     ]
    }
   ],
   "source": [
    "print(test_set.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('loss, acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss, acc')\n",
    "plt.legend(['train loss', 'test loss', 'train acc', 'test acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8640 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "pred_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "pred_set = pred_datagen.flow_from_directory('dataset_pred/', \n",
    "                                              target_size=(400, 400),\n",
    "                                              class_mode='categorical',\n",
    "                                              shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[0.76470596, 0.8117648 , 0.80392164],\n",
       "          [0.76470596, 0.8117648 , 0.80392164],\n",
       "          [0.76470596, 0.8117648 , 0.80392164],\n",
       "          ...,\n",
       "          [0.64705884, 0.68235296, 0.6784314 ],\n",
       "          [0.64705884, 0.68235296, 0.6784314 ],\n",
       "          [0.64705884, 0.68235296, 0.6784314 ]],\n",
       " \n",
       "         [[0.76470596, 0.8117648 , 0.80392164],\n",
       "          [0.76470596, 0.8117648 , 0.80392164],\n",
       "          [0.76470596, 0.8117648 , 0.80392164],\n",
       "          ...,\n",
       "          [0.64705884, 0.68235296, 0.6784314 ],\n",
       "          [0.64705884, 0.68235296, 0.6784314 ],\n",
       "          [0.64705884, 0.68235296, 0.6784314 ]],\n",
       " \n",
       "         [[0.76470596, 0.8117648 , 0.80392164],\n",
       "          [0.76470596, 0.8117648 , 0.80392164],\n",
       "          [0.76470596, 0.8117648 , 0.80392164],\n",
       "          ...,\n",
       "          [0.64705884, 0.68235296, 0.6784314 ],\n",
       "          [0.64705884, 0.68235296, 0.6784314 ],\n",
       "          [0.64705884, 0.68235296, 0.6784314 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.18039216, 0.19215688, 0.21176472],\n",
       "          [0.18823531, 0.20000002, 0.21960786],\n",
       "          [0.20000002, 0.21960786, 0.23529413],\n",
       "          ...,\n",
       "          [0.61960787, 0.6509804 , 0.65882355],\n",
       "          [0.61960787, 0.6509804 , 0.65882355],\n",
       "          [0.6156863 , 0.654902  , 0.65882355]],\n",
       " \n",
       "         [[0.18431373, 0.19607845, 0.22352943],\n",
       "          [0.18039216, 0.19215688, 0.21960786],\n",
       "          [0.19215688, 0.21176472, 0.227451  ],\n",
       "          ...,\n",
       "          [0.61960787, 0.6509804 , 0.65882355],\n",
       "          [0.61960787, 0.6509804 , 0.65882355],\n",
       "          [0.6156863 , 0.654902  , 0.65882355]],\n",
       " \n",
       "         [[0.21568629, 0.227451  , 0.25490198],\n",
       "          [0.19607845, 0.20784315, 0.23529413],\n",
       "          [0.20784315, 0.227451  , 0.2509804 ],\n",
       "          ...,\n",
       "          [0.61960787, 0.6509804 , 0.65882355],\n",
       "          [0.61960787, 0.6509804 , 0.65882355],\n",
       "          [0.6156863 , 0.654902  , 0.65882355]]],\n",
       " \n",
       " \n",
       "        [[[0.07450981, 0.08627451, 0.15294118],\n",
       "          [0.07450981, 0.08627451, 0.15294118],\n",
       "          [0.07450981, 0.08627451, 0.15294118],\n",
       "          ...,\n",
       "          [0.07058824, 0.08235294, 0.14117648],\n",
       "          [0.07058824, 0.08235294, 0.14117648],\n",
       "          [0.07058824, 0.08235294, 0.14117648]],\n",
       " \n",
       "         [[0.07450981, 0.08627451, 0.15294118],\n",
       "          [0.07450981, 0.08627451, 0.15294118],\n",
       "          [0.07450981, 0.08627451, 0.15294118],\n",
       "          ...,\n",
       "          [0.07058824, 0.08235294, 0.14117648],\n",
       "          [0.07058824, 0.08235294, 0.14117648],\n",
       "          [0.07058824, 0.08235294, 0.14117648]],\n",
       " \n",
       "         [[0.07450981, 0.08627451, 0.15294118],\n",
       "          [0.07450981, 0.08627451, 0.15294118],\n",
       "          [0.07450981, 0.08627451, 0.15294118],\n",
       "          ...,\n",
       "          [0.07058824, 0.08235294, 0.14117648],\n",
       "          [0.07058824, 0.08235294, 0.14117648],\n",
       "          [0.07058824, 0.08235294, 0.14117648]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.5294118 , 0.85098046, 1.        ],\n",
       "          [0.5294118 , 0.85098046, 1.        ],\n",
       "          [0.5294118 , 0.85098046, 1.        ],\n",
       "          ...,\n",
       "          [0.5529412 , 0.86274517, 0.9843138 ],\n",
       "          [0.5568628 , 0.86666673, 0.9960785 ],\n",
       "          [0.5529412 , 0.8588236 , 1.        ]],\n",
       " \n",
       "         [[0.5254902 , 0.85098046, 1.        ],\n",
       "          [0.5294118 , 0.85098046, 1.        ],\n",
       "          [0.5294118 , 0.85098046, 1.        ],\n",
       "          ...,\n",
       "          [0.56078434, 0.8705883 , 0.98823535],\n",
       "          [0.56078434, 0.8705883 , 1.        ],\n",
       "          [0.5529412 , 0.86666673, 1.        ]],\n",
       " \n",
       "         [[0.5254902 , 0.85098046, 1.        ],\n",
       "          [0.5254902 , 0.85098046, 1.        ],\n",
       "          [0.5294118 , 0.85098046, 1.        ],\n",
       "          ...,\n",
       "          [0.5647059 , 0.882353  , 0.9960785 ],\n",
       "          [0.5647059 , 0.87843144, 1.        ],\n",
       "          [0.5568628 , 0.8705883 , 1.        ]]],\n",
       " \n",
       " \n",
       "        [[[0.03529412, 0.04705883, 0.08235294],\n",
       "          [0.03529412, 0.04705883, 0.08235294],\n",
       "          [0.03529412, 0.04705883, 0.08235294],\n",
       "          ...,\n",
       "          [0.03137255, 0.03529412, 0.05490196],\n",
       "          [0.03137255, 0.03529412, 0.05490196],\n",
       "          [0.03137255, 0.03529412, 0.05490196]],\n",
       " \n",
       "         [[0.03529412, 0.04705883, 0.08235294],\n",
       "          [0.03529412, 0.04705883, 0.08235294],\n",
       "          [0.03529412, 0.04705883, 0.08235294],\n",
       "          ...,\n",
       "          [0.03137255, 0.03529412, 0.05490196],\n",
       "          [0.03137255, 0.03529412, 0.05490196],\n",
       "          [0.03137255, 0.03529412, 0.05490196]],\n",
       " \n",
       "         [[0.03529412, 0.04705883, 0.08235294],\n",
       "          [0.03529412, 0.04705883, 0.08235294],\n",
       "          [0.03529412, 0.04705883, 0.08235294],\n",
       "          ...,\n",
       "          [0.03137255, 0.03529412, 0.05490196],\n",
       "          [0.03137255, 0.03529412, 0.05490196],\n",
       "          [0.03137255, 0.03529412, 0.05490196]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.03529412, 0.03921569, 0.05490196],\n",
       "          [0.03529412, 0.03921569, 0.05882353],\n",
       "          [0.03529412, 0.03921569, 0.05882353],\n",
       "          ...,\n",
       "          [0.03137255, 0.03529412, 0.05490196],\n",
       "          [0.03137255, 0.03529412, 0.05490196],\n",
       "          [0.03137255, 0.03529412, 0.05490196]],\n",
       " \n",
       "         [[0.02745098, 0.04313726, 0.05490196],\n",
       "          [0.02745098, 0.03921569, 0.05882353],\n",
       "          [0.02745098, 0.03921569, 0.05882353],\n",
       "          ...,\n",
       "          [0.03137255, 0.03529412, 0.05490196],\n",
       "          [0.03137255, 0.03529412, 0.05490196],\n",
       "          [0.03137255, 0.03529412, 0.05490196]],\n",
       " \n",
       "         [[0.02745098, 0.04313726, 0.05490196],\n",
       "          [0.02745098, 0.03921569, 0.05882353],\n",
       "          [0.02745098, 0.03921569, 0.05882353],\n",
       "          ...,\n",
       "          [0.03137255, 0.03529412, 0.05490196],\n",
       "          [0.03137255, 0.03529412, 0.05490196],\n",
       "          [0.03137255, 0.03529412, 0.05490196]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0.01176471, 0.01568628, 0.02352941],\n",
       "          [0.01176471, 0.01568628, 0.02352941],\n",
       "          [0.01176471, 0.01568628, 0.02352941],\n",
       "          ...,\n",
       "          [0.01176471, 0.01568628, 0.02352941],\n",
       "          [0.01176471, 0.01568628, 0.02352941],\n",
       "          [0.01176471, 0.01568628, 0.02352941]],\n",
       " \n",
       "         [[0.01176471, 0.01568628, 0.02352941],\n",
       "          [0.01176471, 0.01568628, 0.02352941],\n",
       "          [0.01176471, 0.01568628, 0.02352941],\n",
       "          ...,\n",
       "          [0.01176471, 0.01568628, 0.02352941],\n",
       "          [0.01176471, 0.01568628, 0.02352941],\n",
       "          [0.01176471, 0.01568628, 0.02352941]],\n",
       " \n",
       "         [[0.01176471, 0.01568628, 0.02352941],\n",
       "          [0.01176471, 0.01568628, 0.02352941],\n",
       "          [0.01176471, 0.01568628, 0.02352941],\n",
       "          ...,\n",
       "          [0.01176471, 0.01568628, 0.02352941],\n",
       "          [0.01176471, 0.01568628, 0.02352941],\n",
       "          [0.01176471, 0.01568628, 0.02352941]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.06666667, 0.12156864, 0.29803923],\n",
       "          [0.09411766, 0.14901961, 0.3254902 ],\n",
       "          [0.34901962, 0.40000004, 0.5764706 ],\n",
       "          ...,\n",
       "          [0.23137257, 0.28235295, 0.44705886],\n",
       "          [0.25882354, 0.30980393, 0.47450984],\n",
       "          [0.25882354, 0.30980393, 0.47450984]],\n",
       " \n",
       "         [[0.0509804 , 0.10588236, 0.28235295],\n",
       "          [0.02745098, 0.08235294, 0.25882354],\n",
       "          [0.2627451 , 0.3137255 , 0.4901961 ],\n",
       "          ...,\n",
       "          [0.24313727, 0.2901961 , 0.454902  ],\n",
       "          [0.24705884, 0.29803923, 0.46274513],\n",
       "          [0.25882354, 0.30980393, 0.47450984]],\n",
       " \n",
       "         [[0.14509805, 0.20000002, 0.37647063],\n",
       "          [0.08627451, 0.14117648, 0.31764707],\n",
       "          [0.25882354, 0.30980393, 0.48627454],\n",
       "          ...,\n",
       "          [0.27058825, 0.31764707, 0.48235297],\n",
       "          [0.29411766, 0.34117648, 0.5058824 ],\n",
       "          [0.33333334, 0.38823533, 0.5411765 ]]],\n",
       " \n",
       " \n",
       "        [[[0.01568628, 0.01960784, 0.03529412],\n",
       "          [0.01568628, 0.01960784, 0.03529412],\n",
       "          [0.01568628, 0.01960784, 0.03529412],\n",
       "          ...,\n",
       "          [0.01960784, 0.02352941, 0.03921569],\n",
       "          [0.01960784, 0.02352941, 0.03921569],\n",
       "          [0.01960784, 0.02352941, 0.03921569]],\n",
       " \n",
       "         [[0.01568628, 0.01960784, 0.03529412],\n",
       "          [0.01568628, 0.01960784, 0.03529412],\n",
       "          [0.01568628, 0.01960784, 0.03529412],\n",
       "          ...,\n",
       "          [0.01960784, 0.02352941, 0.03921569],\n",
       "          [0.01960784, 0.02352941, 0.03921569],\n",
       "          [0.01960784, 0.02352941, 0.03921569]],\n",
       " \n",
       "         [[0.01568628, 0.01960784, 0.03529412],\n",
       "          [0.01568628, 0.01960784, 0.03529412],\n",
       "          [0.01568628, 0.01960784, 0.03529412],\n",
       "          ...,\n",
       "          [0.01960784, 0.02352941, 0.03921569],\n",
       "          [0.01960784, 0.02352941, 0.03921569],\n",
       "          [0.01960784, 0.02352941, 0.03921569]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.01568628, 0.01960784, 0.03529412],\n",
       "          [0.01568628, 0.01960784, 0.03529412],\n",
       "          [0.01568628, 0.01960784, 0.03529412],\n",
       "          ...,\n",
       "          [0.01176471, 0.02352941, 0.04313726],\n",
       "          [0.        , 0.00784314, 0.02745098],\n",
       "          [0.        , 0.        , 0.01960784]],\n",
       " \n",
       "         [[0.01568628, 0.01960784, 0.03529412],\n",
       "          [0.01568628, 0.01960784, 0.03529412],\n",
       "          [0.01568628, 0.01960784, 0.03529412],\n",
       "          ...,\n",
       "          [0.04313726, 0.05490196, 0.08235294],\n",
       "          [0.02352941, 0.03529412, 0.05490196],\n",
       "          [0.00784314, 0.01960784, 0.03921569]],\n",
       " \n",
       "         [[0.01568628, 0.01960784, 0.03529412],\n",
       "          [0.01568628, 0.01960784, 0.03529412],\n",
       "          [0.01568628, 0.01960784, 0.03529412],\n",
       "          ...,\n",
       "          [0.08627451, 0.09803922, 0.1254902 ],\n",
       "          [0.0627451 , 0.07450981, 0.09411766],\n",
       "          [0.04705883, 0.05882353, 0.07843138]]],\n",
       " \n",
       " \n",
       "        [[[0.08627451, 0.09803922, 0.16470589],\n",
       "          [0.08627451, 0.09803922, 0.16470589],\n",
       "          [0.08627451, 0.09803922, 0.16470589],\n",
       "          ...,\n",
       "          [0.10196079, 0.12156864, 0.19607845],\n",
       "          [0.10196079, 0.12156864, 0.19607845],\n",
       "          [0.10196079, 0.12156864, 0.19607845]],\n",
       " \n",
       "         [[0.08627451, 0.09803922, 0.16470589],\n",
       "          [0.08627451, 0.09803922, 0.16470589],\n",
       "          [0.08627451, 0.09803922, 0.16470589],\n",
       "          ...,\n",
       "          [0.10196079, 0.12156864, 0.19607845],\n",
       "          [0.10196079, 0.12156864, 0.19607845],\n",
       "          [0.10196079, 0.12156864, 0.19607845]],\n",
       " \n",
       "         [[0.08627451, 0.09803922, 0.16470589],\n",
       "          [0.08627451, 0.09803922, 0.16470589],\n",
       "          [0.08627451, 0.09803922, 0.16470589],\n",
       "          ...,\n",
       "          [0.10196079, 0.12156864, 0.19607845],\n",
       "          [0.10196079, 0.12156864, 0.19607845],\n",
       "          [0.10196079, 0.12156864, 0.19607845]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.07450981, 0.08627451, 0.14509805],\n",
       "          [0.07450981, 0.08627451, 0.14509805],\n",
       "          [0.07450981, 0.08627451, 0.14509805],\n",
       "          ...,\n",
       "          [0.06666667, 0.09411766, 0.1254902 ],\n",
       "          [0.05882353, 0.08627451, 0.10980393],\n",
       "          [0.0509804 , 0.08235294, 0.09411766]],\n",
       " \n",
       "         [[0.07450981, 0.08627451, 0.14509805],\n",
       "          [0.07450981, 0.08627451, 0.14509805],\n",
       "          [0.07450981, 0.08627451, 0.14509805],\n",
       "          ...,\n",
       "          [0.07450981, 0.10980393, 0.14509805],\n",
       "          [0.0627451 , 0.09803922, 0.11764707],\n",
       "          [0.05490196, 0.08627451, 0.09803922]],\n",
       " \n",
       "         [[0.07450981, 0.08627451, 0.14509805],\n",
       "          [0.07450981, 0.08627451, 0.14509805],\n",
       "          [0.07450981, 0.08627451, 0.14509805],\n",
       "          ...,\n",
       "          [0.08235294, 0.1137255 , 0.15686275],\n",
       "          [0.06666667, 0.10196079, 0.12941177],\n",
       "          [0.04705883, 0.08235294, 0.10196079]]]], dtype=float32),\n",
       " array([[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_set1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8640, 3)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200001001100011110010110122011101101011000100110012110201111001000100011120110000100210011021201001011000120000101111111000111110001110000000110101000111021010121011121000101001010010021100101111112211110110011011110111000000211110211010111110101100110011001111101201011101101001000001112111011011001100100010110110110010010001100101010112001011010010122000000101112100112101121010011111101120101111111011001110001101100010001110011111120100010000101001001011211010121011000110110111211110010011110100100101011211200000001000101021011001101000000101112101001001011110010010000110001010111110101120200111001000000011001011100110000211110110001101200110101102010100100111011000000101101010100001200111110021100101100010000010011201001110000001010000201010111010000110001100001101002111010110010000111111101100101001000211201001101101000000000101110001100122101100101011201121010111111000100010000010001210101100101011000011000210111010101111101110011001011011111111111001101010100000111010010110201001010021010000100101100001100111010011110111210111001010000020112111111110110000001101111100000101100110011000120100010021211111111010010000111110201112010010111100011011121101101110011000012011021110100000010100221100000110111101011011111101111111101121200110000010111010001010000110200110000100011100000210000000210112112010121001100200220111111110101111112101110111001000010102000102110011211111011002100101010111102110111012002100101011112111011101011001011000110101010011012220111110001011100001111001101000100100001102000010000010100011100120102010110100100100000011101011001101000101210201100101100001101010001100001001100110000010011111100001200020011010000110010111011100011000001000111001100111101100101010000010011000100011100021010000011112110111121111110111200002101111012000111000011110101120110010112012112111010111210101110111000110001011100100100010110111111100011111111010120100010002110010110111011101001010111010111100000011100112110011110100100101112001110101100102111011110101101111100001101120110010101001110101000001100010111011010101101002101110100100100110100010000001111111101212111111120011111210102001010111112010100111001100011010101001110012001011000110201100200100101200000100111010211110020211101101102010012100110012102010110101011011110111110011010101101110111110101121120002011112100120111101001110110101011011001011111010111021100001101100010100120101100011100011111000010110020001111101011010021101100100001000111000010001111100001001100101101010111001011002110101100010000101010111010001011011000111000100011011111020011100001101112001212120100021211101020221011101112110001101001101000110011001010001111101201110011101001201110111101010010000111000111020111100111112011011100110110101101001012000101112012100120000100010110100110010001010010001000110110120000101101000011100102101001102101110101111001100011100011010111211010100101010000001111110111010111111011010010211011112121111001102011100001111101010110101100111112111101011110202111010011111011111011101101110021101111000120110011011011111101011111112000110101120012111011101111010110111111121111111101101011100211111111110111110011010100111111111101011111010011111020101110111111101111111122100211210110110110100011011111111200011112111112011110111111211101011110111011110111111111111001111011110010111110111111011111011121100111011121011211120101211110111100011111111000011100011110111100111001001111121001110110111111011110011011211101111101110111111101101101111001210111011100100111111000111111011110001111110100211001111101112100011110110111011100111000001110111011101011211011111111111110101111011101101011111111111011001110011001001111101111111101110010211111011011111110011111110111111011000101011111121001011010101100121011110001010111111111111110101011100000021111110100102111001101110001120001111110211110001110011111110101111110111110102111111001100101112001111110110111000101111121111111100110001111101101111111001011000101111111111110211011010101111110111101111211110010101111111021010111210111211001111110100111011110121110101121111011010120111111110111111010101110111110011211010110111110110111011100101110212101011011110000110211111101111101110112101111110111211101000101110120010010111111111110110011100111101201111101110101110111111101111111111010110110101111101001010111111111001001110101020110111111110111110002110110110111001101110111111101110110101011011111111021001111121001110021111111120010111021111011111111101111110110021101101110110111101110112211100111111111210101111111011011121001101010101100111022002111101100000111010100011200111011211121111111112111111111101101111111111011001001011111111111110101112101201111101111111011011111111101100110110110100111111110101111111110101011100101111102121001111011001112111011010111101211000111211100011111111111111121101201111110111101111101110011121111111001111010110011101111011100121010111111011100010111111111100100012111011101110011101111101001011011111001101101101101100101110111120111001111110111001001111111101010120101012011111110110111011010011111211002111111111011011111001101011111011111010210110011101100010011121112010111011101010011100110101111111111011111102100100111111011101011111111001111110111101111111101001111111111100102111111121111100111011111011110111111110110101111101001111101111121100111011110111102110111011111211111011011211111111111111001100111211111011111110011110011111111011111111001101121110111011111111110111111011101001101001111011020111100110111111010001111121101110111111101100001101110011110110001111111111110110011110111011111011110111100100111111111112111210111111101111111111110010110121111011110122101110011010102101100110110101121110110011111011110111101100001210111101110211210111110101001011101001010120011110100001111110011111110111111011000110011101122001111100201001022000012120001011110010021002112110111101012111012110102122200211011022110110020001010100121100102000001100110221221100220111010001121021120110110210011222101112001011110010101111212021211110110110000110221110010121020112100200211000122121021102210020011211000012201210102101102220112012000221112101011211010212000002021021001101102101110221022002011110201102121210210101101101010000111000120110000011100000010110011012200020100000110010100002001011000000100211111002201120121122012110201221222120021202000101000112101100101120101100201101002002002001002210211210101100001010121010012102111100121101121001100002011200110122010000211020021212010010000121101020100210111221110001201111001211112010220001111000210022000120120111211012001201101121121010221211112202012102100012211001010201121201201120000010101000021010211001010221100001001210010112221100102010000220110120011001002010001012122120012010002000211111110121001000120111021000010002211101100112001011110100011000222200201022010122012112122001002000012110020022121000201211221011012000010001211010022011101100122022001001112010201100100212110000021000021111200010210001221100200210120101221120200000102102211011010110001011020210101111100200100022110110010201120101112111001101111010102000202120122100120010111211010100102101020001211100010211010001110010101222001021001211111002210102010011100002000101111100002100220101200100011002202022110222012101102021120220220211022000010001102120101101221011020211212220220101210201002120102011001110210110021100020200120121201102120000101101012021001100100202102110110102120110001001101121010100010210110110111112010100002200111210000110121012020100101101102111112200110110022200010010112112021011001110100000011010110102101111012000000211021100102000012210101002102111120100121001110202000100110110010010100001211100202100001111201101122000220120110101011010001112011111101100212001110112212201102120211111002101112000000101012010012202111210001002011210121000101100010011102201012201201002000011212210011200012000202101001001012000212120102001012220202110100021221012101200221102200110202100102010001011100201000010012012010020200120101210000100111211001201111120020011012122002201102100221110202120020022101110211010201001101001001200120110212011001112202121000202100002021202101201110101202221101200010120011200012010101220020002010002012010120211210022200111100111001211122021010201100200200110020010012210010011011010010020021122011100010021002021120101212220000021222101211212112200010101011101112000021101200100120020101111000000002020000001012200002101101120202011101000101021210100000021000112022110021020111102000000100211001211102111100001020222102102111111122010010020100210110020111200001110001112101112111211111102100111021020110012020012110020002110200100101100012011011202012000022211210100001200120100101112212002200021100011101101000000121"
     ]
    }
   ],
   "source": [
    "for i in range(8640):\n",
    "    print(np.argmax(pred[i]), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.57      0.58      2880\n",
      "           1       0.55      0.66      0.60      2880\n",
      "           2       0.71      0.58      0.64      2880\n",
      "\n",
      "   micro avg       0.61      0.61      0.61      8640\n",
      "   macro avg       0.62      0.61      0.61      8640\n",
      "weighted avg       0.62      0.61      0.61      8640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model 검증\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pred = model.predict_generator(pred_set)\n",
    "\n",
    "val_preds = np.argmax(pred, axis=-1)\n",
    "val_trues = pred_set.classes\n",
    "\n",
    "print(classification_report(val_trues,val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_generator(pred_set)\n",
    "\n",
    "\n",
    "val_preds = np.argmax(pred, axis=-1)\n",
    "val_trues = pred_set.classes\n",
    "cm = metrics.confusion_matrix(val_trues, val_preds)\n",
    "\n",
    "\n",
    "labels = pred_set1.class_indices.keys()\n",
    "precisions, recall, f1_score, _ = metrics.precision_recall_fscore_support(val_trues, val_preds, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2b14311c36d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mco\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2880\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#     print(result, end='')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "# 무표정\n",
    "co=0\n",
    "for i in range(2880):\n",
    "    result = np.argmax(pred[i])\n",
    "#     print(result, end='')\n",
    "    if result==0:\n",
    "        co+=1\n",
    "        \n",
    "print('\\n','Neutral accuracy :', \"%.2f\" % (co/2880.))\n",
    "\n",
    "# 기쁨\n",
    "co=0\n",
    "for i in range(2880, 5760):\n",
    "    result = np.argmax(pred[i])\n",
    "#     print(result, end='')\n",
    "    if result==1:\n",
    "        co+=1\n",
    "        \n",
    "print('\\n','Positive accuracy :', \"%.2f\" % (co/2880.))\n",
    "\n",
    "\n",
    "# 찡그림\n",
    "co=0\n",
    "for i in range(5760,8640):\n",
    "    result = np.argmax(pred[i])\n",
    "#     print(result, end='')\n",
    "    if result==2:\n",
    "        co+=1\n",
    "        \n",
    "print('\\n','Negative accuracy :', \"%.2f\" % (co/2880.))\n",
    "\n",
    "# transfer learning(mobileNetV2)\n",
    "#  Neutral accuracy : 0.45\n",
    "#  Positive accuracy : 0.69\n",
    "#  Negative accuracy : 0.20\n",
    "\n",
    "# transfer learning(mobileNetV2)\n",
    "#  Neutral accuracy : 0.21\n",
    "#  Positive accuracy : 0.82\n",
    "#  Negative accuracy : 0.65\n",
    "\n",
    "# CNN model\n",
    "#  Neutral accuracy : 0.99\n",
    "#  Positive accuracy : 0.79\n",
    "#  Negative accuracy : 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 저장이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "model.save('./save/cnn0520(imagegenerator, 400).h5')\n",
    "print('모델 저장이 완료되었습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 저장이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "model.save('./save/transferlearning0520(imagegenerator, 400).h5')\n",
    "print('모델 저장이 완료되었습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:amazonei_tensorflow_p36]",
   "language": "python",
   "name": "conda-env-amazonei_tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
